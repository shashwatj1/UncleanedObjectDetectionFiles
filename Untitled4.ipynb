{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64d1010-3be2-4674-88b9-53e195bcbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c17bc2-8ccd-4c2d-bbdc-fce3fc07fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8a78f1-a3b0-4b5f-80fc-33132999e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', \n",
    "    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', \n",
    "    'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', \n",
    "    'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', \n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', \n",
    "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', \n",
    "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', \n",
    "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', \n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', \n",
    "    'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e569e8f1-061b-4b92-bac8-467dd07a47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6168d927-276e-4670-8004-702b96931a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b45e0d-0197-4347-81d9-8f069927071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_detected = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ddd5ec-2e59-4e14-908a-4f1aee335a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "last_update_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61706140-45bd-4186-a77d-3f0b514ac57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bdeb16-bc90-4239-a4d9-10c5bd0156a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bed, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 bed, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 bed, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 1 bed, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 1 time\n",
      "Detected chair 1 time\n",
      "\n",
      "0: 384x640 2 persons, 1 bed, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 2 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 2 persons, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bed, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bed, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 2 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 2 time\n",
      "\n",
      "0: 384x640 2 persons, 2 beds, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 2 time\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 beds, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 2 time\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected chair 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 34.0ms\n",
      "Speed: 3.0ms preprocess, 34.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected chair 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 toothbrush, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected chair 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 2 beds, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 chair, 2 beds, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 1 banana, 1 chair, 1 bed, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected chair 1 time\n",
      "Detected bed 1 time\n",
      "Detected banana 1 time\n",
      "Detected tie 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 2 beds, 1 toothbrush, 40.0ms\n",
      "Speed: 5.0ms preprocess, 40.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected toothbrush 1 time\n",
      "Detected chair 1 time\n",
      "Detected bed 2 time\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 15.5ms\n",
      "Speed: 2.0ms preprocess, 15.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n",
      "Detected bed 1 time\n",
      "\n",
      "0: 384x640 1 person, 1 bed, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detected person 1 time\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    classes_detected.clear()\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2- x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "\n",
    "            conf = math.ceil((box.conf[0] * 100)) \n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}%', (max(0, x1), max(35, y1)))\n",
    "            class_name = classNames[cls]\n",
    "            if class_name in classes_detected:\n",
    "                classes_detected[class_name] += 1\n",
    "            else:\n",
    "                classes_detected[class_name] = 1\n",
    "    current_time = time.time()\n",
    "    if current_time - last_update_time >= 4:\n",
    "        for key, value in classes_detected.items():\n",
    "            message = (f\"Detected {key} {value} time\")\n",
    "            print(message)\n",
    "            engine.say(message)\n",
    "            engine.runAndWait()\n",
    "        last_update_time = current_time  \n",
    "    cv2.imshow(\"image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "print(classes_detected)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de22cef9-67a7-412c-9ea1-c24b929c1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Dataset/test2017/test2017/000000018016.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22703806-835e-47ec-8f64-7cf854d98b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Shashwat\\ModelDirectory\\Dataset\\test2017\\test2017\\000000018016.jpg: 448x640 15 persons, 1 baseball bat, 1 baseball glove, 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[246, 240, 229],\n",
       "         [246, 240, 227],\n",
       "         [243, 237, 224],\n",
       "         ...,\n",
       "         [239, 232, 215],\n",
       "         [240, 233, 216],\n",
       "         [240, 233, 216]],\n",
       " \n",
       "        [[246, 239, 224],\n",
       "         [245, 238, 223],\n",
       "         [247, 240, 225],\n",
       "         ...,\n",
       "         [241, 234, 217],\n",
       "         [241, 234, 217],\n",
       "         [241, 234, 217]],\n",
       " \n",
       "        [[250, 243, 228],\n",
       "         [251, 244, 229],\n",
       "         [252, 245, 230],\n",
       "         ...,\n",
       "         [242, 235, 218],\n",
       "         [242, 235, 218],\n",
       "         [243, 236, 219]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[128, 139, 153],\n",
       "         [133, 144, 158],\n",
       "         [135, 148, 162],\n",
       "         ...,\n",
       "         [131, 179, 203],\n",
       "         [164, 213, 239],\n",
       "         [146, 196, 224]],\n",
       " \n",
       "        [[132, 139, 158],\n",
       "         [134, 144, 161],\n",
       "         [134, 147, 163],\n",
       "         ...,\n",
       "         [165, 208, 235],\n",
       "         [133, 174, 206],\n",
       "         [146, 189, 222]],\n",
       " \n",
       "        [[132, 140, 163],\n",
       "         [132, 143, 163],\n",
       "         [131, 145, 163],\n",
       "         ...,\n",
       "         [161, 200, 232],\n",
       "         [160, 196, 232],\n",
       "         [166, 202, 240]]], dtype=uint8)\n",
       " orig_shape: (432, 640)\n",
       " path: 'C:\\\\Users\\\\Shashwat\\\\ModelDirectory\\\\Dataset\\\\test2017\\\\test2017\\\\000000018016.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict2'\n",
       " speed: {'preprocess': 2.004861831665039, 'inference': 13.538360595703125, 'postprocess': 3.0126571655273438}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image_path, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cadbe1-8cdb-4af3-9b61-3ea878d9f30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26364c54-5292-4aae-8267-838249da217c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
